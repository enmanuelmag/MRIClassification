{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = '.'\n",
    "SHAPE = (197, 233, 189)\n",
    "MODEL_PATH = f'{PREFIX}/models/vit/multi_class_5_4/vit_vit_(197, 233, 189)_[128]_0.0001_32_0.1_18_10_361_256_4_[512, 256]_0.15_checkpoint.h5'\n",
    "TF_RECORD_PATH = f'{PREFIX}/data/tfrecords/tf_dataset.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example):\n",
    "  features = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "  }\n",
    "  example = tf.io.parse_single_example(example, features)\n",
    "  image = tf.io.decode_raw(example['image'], tf.float32)\n",
    "  image = tf.reshape(image, SHAPE)\n",
    "  image = tf.reshape(image, (SHAPE[0], SHAPE[1], SHAPE[2]))\n",
    "  #one_hot = tf.one_hot(example['label'], 2)\n",
    "  return image, example['label']\n",
    "\n",
    "def load_tfrecord(tfrecord_path):\n",
    "  dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "  dataset = dataset.map(parse_example)\n",
    "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  #dataset = dataset.cache()\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(layers.Layer):\n",
    "  def __init__(self, hidden_units=[128, 64], dropout_rate=0.1, activation=\"gelu\", kernel_regularizer=None, **kwargs):\n",
    "    super(MLP, self).__init__(**kwargs)\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.hidden_units = hidden_units\n",
    "    self.activation = activation\n",
    "    self.kernel_regularizer = kernel_regularizer\n",
    "    for i, units in enumerate(hidden_units):\n",
    "      setattr(self, f'dense_{i}', layers.Dense(units, activation=self.activation, kernel_regularizer=kernel_regularizer))\n",
    "      setattr(self, f'dropout_{i}', layers.Dropout(dropout_rate))\n",
    "\n",
    "  def get_config(self, **kwargs):\n",
    "    config = super().get_config()\n",
    "    config_dict = {\n",
    "        \"dropout_rate\": self.dropout_rate,\n",
    "        \"hidden_units\": self.hidden_units,\n",
    "        \"activation\": self.activation,\n",
    "        \"kernel_regularizer\": self.kernel_regularizer\n",
    "    }\n",
    "    config.update(config_dict)\n",
    "    return config\n",
    "\n",
    "  def call(self, x, training=None, **kwargs):\n",
    "    for i, _ in enumerate(self.hidden_units):\n",
    "      x = getattr(self, f'dense_{i}')(x)\n",
    "      x = getattr(self, f'dropout_{i}')(x, training=training)\n",
    "    return x\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def get_config(self, **kwargs):\n",
    "      config = super().get_config()\n",
    "      config_dict = {\n",
    "          \"patch_size\": self.patch_size\n",
    "      }\n",
    "      config.update(config_dict)\n",
    "      return config\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim=64, **kwargs):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = layers.Dense(units=self.projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=self.projection_dim\n",
    "        )\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config()\n",
    "      config_dict = {\n",
    "          \"num_patches\": self.num_patches,\n",
    "          \"projection_dim\": self.projection_dim\n",
    "      }\n",
    "\n",
    "      config.update(config_dict)\n",
    "      return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "def plot_3d_array_image(volume_img_array, slice_to_plot=64, cmap='gray'):\n",
    "    plt.imshow(volume_img_array[slice_to_plot], cmap=cmap)\n",
    "    plt.show()\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "    [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(np.array([img_path]))\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "            #print(preds, preds.shape)\n",
    "            #print('Predicted class:', pred_index.numpy())\n",
    "        class_channel = preds[:, pred_index]\n",
    "        #print('class_channel', class_channel, class_channel.shape)\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    #print('last_conv_layer_output', last_conv_layer_output.shape)\n",
    "    #print('grads', grads.shape)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    #print('pooled_grads', pooled_grads.shape)\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    #print('last_conv_layer_output', last_conv_layer_output.shape)\n",
    "    #print('pooled_grads[..., tf.newaxis]', pooled_grads[..., tf.newaxis].shape)\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    #print('heatmap', heatmap.shape)\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    #print('heatmap', heatmap.shape)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = load_tfrecord(TF_RECORD_PATH)\n",
    "mri_x_array = None\n",
    "mri_y_array = None\n",
    "\n",
    "mri_classes = {}\n",
    "\n",
    "for x, y in tf_dataset:\n",
    "  mri_y_array = y.numpy()\n",
    "  if mri_y_array not in mri_classes:\n",
    "    mri_classes[mri_y_array] = x.numpy()\n",
    "\n",
    "  if len(mri_classes) == 2:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = SHAPE\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, custom_objects={ 'MLP': MLP, 'Patches': Patches, 'PatchEncoder': PatchEncoder }, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = model.layers[1].name\n",
    "\n",
    "img_path = mri_x_array\n",
    "slice_to_plot = 64\n",
    "\n",
    "plot_3d_array_image(img_path, slice_to_plot, cmap='gray')\n",
    "\n",
    "gradcam_heatmap = make_gradcam_heatmap(img_path, model, last_conv_layer_name, pred_index=None)\n",
    "\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = model.layers[1].name\n",
    "\n",
    "grad_model = tf.keras.models.Model(\n",
    "[model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    ")\n",
    "# Then, we compute the gradient of the top predicted class for our input image\n",
    "# with respect to the activations of the last conv layer\n",
    "with tf.GradientTape() as tape:\n",
    "    last_conv_layer_output, preds = grad_model(np.array([img_path]))\n",
    "    if pred_index is None:\n",
    "        pred_index = tf.argmax(preds[0])\n",
    "        print(preds, preds.shape)\n",
    "        print('Predicted class:', pred_index.numpy())\n",
    "    class_channel = preds[:, pred_index]\n",
    "    print('class_channel', class_channel, class_channel.shape)\n",
    "# This is the gradient of the output neuron (top predicted or chosen)\n",
    "# with regard to the output feature map of the last conv layer\n",
    "grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "print('last_conv_layer_output', last_conv_layer_output.shape)\n",
    "print('grads', grads.shape)\n",
    "\n",
    "# This is a vector where each entry is the mean intensity of the gradient\n",
    "# over a specific feature map channel\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "print('pooled_grads', pooled_grads.shape)\n",
    "\n",
    "# We multiply each channel in the feature map array\n",
    "# by \"how important this channel is\" with regard to the top predicted class\n",
    "# then sum all the channels to obtain the heatmap class activation\n",
    "last_conv_layer_output = last_conv_layer_output[0]\n",
    "print('last_conv_layer_output', last_conv_layer_output.shape)\n",
    "print('pooled_grads[..., tf.newaxis]', pooled_grads[..., tf.newaxis].shape)\n",
    "heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "print('heatmap', heatmap.shape)\n",
    "heatmap = tf.squeeze(heatmap)\n",
    "print('heatmap', heatmap.shape)\n",
    "\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tfAnime')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54fc5817759acf8623396abca65217b207b5805927b1176ef1418a5fdb9e7b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
